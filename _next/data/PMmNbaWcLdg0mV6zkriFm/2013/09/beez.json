{"pageProps":{"id":"2013-09-04-beez","year":"2013","month":"09","day":"04","slug":"beez","content":"<img src=\"/images/2013/09/beez.png\" alt=\"\" class=\"thumbnail-left\" />\n\n<p>Here is <strong>Beez</strong>, a web real-time audio experiment \nusing smartphones as synthesizer effect controllers.</p>\n<p>This is our second <a href=\"https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html\">Web Audio API</a> experiment made in one Hackday at <a href=\"http://zenexity.com\">Zenexity</a> (now Zengularity).</p>\n<p>This time, we were much more focused on having the best <strong>latency performance</strong>:\nwe used the bleeding-edge <a href=\"http://www.w3.org/TR/webrtc/\">WebRTC</a> technology,\nwhich allows you to link clients in Peer-to-Peer instead of a classical Client-Server architecture.</p>\n<ul>\n<li><a href=\"http://github.com/gre/beez\">The project on Github</a></li>\n<li><a href=\"http://beez.greweb.fr/\">Test it now!</a> (Chrome)</li>\n</ul>\n<h3 id=\"live-demo-of-the-hackday-application\">Live demo of the Hackday application</h3>\n<iframe width=\"640\" height=\"480\" src=\"//www.youtube.com/embed/QwU6IMNLF0o\" frameborder=\"0\" allowfullscreen></iframe>\n\n<p><em>Bonus for the one who recognizes the melody :-)</em></p>\n<!--more-->\n\n<h2 id=\"the-experiment\">The Experiment</h2>\n<p>The experiment consists in controlling an audio stream running on a desktop web page with \nsome audio effect pads running on phones via a mobile web interface.\n<strong>Our main goal was to make the best real-time experience.</strong></p>\n<h3 id=\"hive-and-bees\">Hive and Bees</h3>\n<p>An <strong>Hive</strong> is controlled by different <strong>Bees</strong>, eventhing connected in Peer-to-Peer (via WebRTC).</p>\n<h4 id=\"the-hive\">The Hive</h4>\n<p>The <strong>Hive</strong> is a web page where the sound is generated and visualized <em>(Web Audio API)</em>.\nIt also shows you in real-time the different effects XY pads and allows you to control them.</p>\n<p><img src=\"/images/2013/09/hive.png\" alt=\"\"></p>\n<h4 id=\"a-bee\">A Bee</h4>\n<p>The <strong>Bee</strong> is a mobile web page which allows you to control the different sound effects with XY pads.\nIt only works on Android Chrome now <em>(WebRTC required)</em>.</p>\n<p><img src=\"/images/2013/09/bee.png\" alt=\"\"></p>\n<h3 id=\"audio-tech\">Audio tech</h3>\n<p>We used <a href=\"https://dvcs.w3.org/hg/audio/raw-file/tip/webaudio/specification.html\">Web Audio API</a> for generating the sound client-side on the Hive:</p>\n<p>We have a note sequencer which plays a <em><strong>famous melody</strong></em> through a <a href=\"/2013/08/FM-audio-api\">Frequency Modulator</a> and different other effects.\nSome controls allow you to change the <strong>BPM</strong>, <strong>gain</strong> of the carrier and the modulator, <strong>finetune</strong>, \nfrequency <strong>multiplicator</strong> (0.25, 0.5, 1, 1.5, 2) of the carrier and the modulator,\n<strong>reverbation</strong>, <strong>filter</strong> (frequency and resonance).\nThere is also a delay effect made on both left and right channels to produce a cool stereo effect.</p>\n<p>That&#39;s quite basic audio stuff so far, I can&#39;t wait to experiment deeper and try to generate more complex sounds with that awesome Audio API.\nAgain, our main goal was to make a P2P connection between the hive and its bees.</p>\n<h3 id=\"network-architecture\">Network architecture</h3>\n<img src=\"/images/2013/09/beez_arch.png\" alt=\"\" class=\"thumbnail-left\" />\n**Every bee are connected to the hive with a bi-directionnal Peer-to-Peer connection thanks to [WebRTC][webrtc].**\n\n<p>Everytime a (bee) user moves an effect controller with his phone, a position event is sent to the hive.</p>\n<p>Basically:</p>\n<pre><code class=\"language-javascript\">xyAxis.on(&quot;change:x change:y&quot;, function () {\n  hive.send([&quot;tabxy&quot;, this.get(&quot;tab&quot;), this.get(&quot;x&quot;), this.get(&quot;y&quot;)]);\n});\n</code></pre>\n<p><em>As you can see, we used Backbone.js models for events.</em></p>\n<p>However, A lot of Touch events per second can be triggered by an Android device, and it may depends on the device speed. We shouldn&#39;t send to the network all of these events because it can saturate it and cause some lags. To avoid that we need to <strong>throttle the touch events before sending the event to the network</strong>.</p>\n<p>This is done transparently with the <a href=\"http://underscorejs.org/#throttle\"><code>_.throttle</code></a> function and we choose to <strong>throttle by 50 milliseconds</strong> which is <strong>about 20 events per second</strong> which is ok for human eye.</p>\n<pre><code class=\"language-javascript\">xyAxis.on(&quot;change:x change:y&quot;, _.throttle(function () {\n  hive.send([&quot;tabxy&quot;, this.get(&quot;tab&quot;), this.get(&quot;x&quot;), this.get(&quot;y&quot;)]);\n}, 50));\n</code></pre>\n<p>We use different other events:</p>\n<ul>\n<li>A bee can send <code>&quot;tabxychanging&quot;</code> and <code>&quot;tabopen&quot;</code> respectively to informs the cursor has been pressed/released and to inform a new tab has been opened.</li>\n<li>When a Hive receive a <code>&quot;tabopen&quot;</code>, it will send back to the bee a <code>&quot;tabxy&quot;</code> event in order to inform what is the current value of that tab so we can init the cursor to the current xy axis position on the bee interface.</li>\n</ul>\n<h2 id=\"websockets-vs-webrtc\">WebSockets vs WebRTC</h2>\n<img src=\"/images/2013/09/websocket.png\" class=\"thumbnail-left\" />\n\n<p>Most &quot;real-time&quot; web experiments you see on the Internet today use <a href=\"http://www.w3.org/TR/websockets/\">WebSockets</a>.\nWebSockets are good, it&#39;s a significant evolution from the Ajax years.</p>\n<p>WebSocket is a protocol on top of TCP, which <strong>links a browser with a server in a bidirectional text communication</strong>.\nGetting 2 clients to communicate generally consists in broadcasting messages from the server to all clients \n(see the schema).</p>\n<p><strong>This architecture has some advantages:</strong></p>\n<ul>\n<li>Simple to understand, Easy to use.</li>\n<li>We can easily implement some server validation.</li>\n</ul>\n<p><strong>But also has some drawbacks:</strong></p>\n<ul>\n<li>Not always easy to traverse <strong>proxies</strong>. <em>(e.g. through an nginx front server)</em></li>\n<li>Only text communication.</li>\n<li><strong>bandwith</strong> intensive. <em>(all the bandwidth goes back and forth with your server)</em></li>\n<li><strong>CPU</strong> intensive. <em>(e.g. receiving 20 messages per second from 10 clients can be a lot for a small server, especially if you are doing some message processing)</em></li>\n</ul>\n<p>(The last two &quot;cons&quot; are scalability issues)</p>\n<hr style=\"clear:both\" />\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ac/Logo-webrtc.png\" class=\"thumbnail-left\" />\n\n<p><a href=\"http://www.webrtc.org/\">WebRTC</a> (<em>Web Real Time Communication</em>), \nis a new web technology which helps to connect browsers in a <strong>Peer to Peer</strong> way.</p>\n<p>WebRTC has been designed for transfering binary data like files, audio, video (e.g. a webcam stream).\nOf-course, we can still use it for text.</p>\n<br style=\"clear:both\" />\n\n<img src=\"/images/2013/09/webrtc.png\" class=\"thumbnail-right\" />\n\n<p>Unlike WebSockets, multiple steps are required to <strong>establish a P2P connection between two web clients</strong>.\nIt is due to the fact that the two clients must resolve the closest network path to communicate with each other.\nThat resolving phase requires a communication between the clients, and for that we can use WebSockets as a <em>&quot;Control Channel&quot;</em>.</p>\n<p>But once the two web clients are connected, they basically don&#39;t need the web server anymore and can <strong>communicate directly together</strong>.\nIf the two clients are in the same local network, they should directly communicate through that local network.\nThat <strong>reduces the server load</strong> and should significantly <strong>decrease the latency</strong>.</p>\n<h3 id=\"playframework--akka-actors\">Playframework / Akka Actors</h3>\n<p><a href=\"http://playframework.com/\">Playframework</a> has been used on the server side for making that WebSocket Control Channel,\nand akka was convenient for handling peer communication and rooms management.</p>\n<h2 id=\"about-the-melody\">About the melody</h2>\n<p>You still didn&#39;t guess where does the melody came from?</p>\n<p>Well, here is the answer:</p>\n<iframe width=\"640\" height=\"480\" src=\"//www.youtube.com/embed/3rU_ei_x0Ag\" frameborder=\"0\" allowfullscreen></iframe>\n\n<h2 id=\"awesome-team\">Awesome team!</h2>\n<p>Finally I want to thanks my team-mates: <a href=\"http://twitter.com/mrspeaker\">@mrspeaker</a>, <a href=\"http://twitter.com/etaty\">@etaty</a>, <a href=\"http://twitter.com/NicuPrinFum\">@NicuPrinFum</a>, <a href=\"http://twitter.com/drfars\">@drfars</a>, <a href=\"http://twitter.com/srenaultcontact\">@srenaultcontact</a>\nwith who we were able to make that demo from scratch in one day!</p>\n","data":{"title":"Beez, WebRTC + Audio API","description":"Here is Beez, a web real-time audio experiment using smartphones as synthesizer effect controllers. This is our second Web Audio API experiment made in one Hackday at Zenexity.","thumbnail":"/images/2013/09/beez.png","author":"Gaetan","layout":"post","tags":["WebRTC","audio","hackday"]}},"__N_SSG":true}