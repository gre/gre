<!DOCTYPE html><html><head><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><meta name="author" content="Gaëtan Renaudeau"/><meta name="description" content="This third article reveals the technique used to render the screen display itself."/><meta name="keywords" content="NFT"/><meta name="HandheldFriendly" content="True"/><meta name="MobileOptimized" content="320"/><meta name="viewport" content="width=device-width, initial-scale=1"/><meta name="twitter:card" content="summary"/><meta name="twitter:site" content="@greweb"/><meta name="twitter:title" content="GNSP – the Nano screen rendering"/><meta name="og:title" content="GNSP – the Nano screen rendering"/><meta name="twitter:description" content="This third article reveals the technique used to render the screen display itself."/><meta name="twitter:creator" content="@greweb"/><meta name="og:image" content="http://greweb.me//images/2022/gnsp/screen-thumbnail.png"/><meta name="twitter:image" content="http://greweb.me//images/2022/gnsp/screen-thumbnail.png"/><link rel="image_src" href="http://greweb.me//images/2022/gnsp/screen-thumbnail.png"/><title>@greweb - GNSP – the Nano screen rendering</title><link href="http://fonts.googleapis.com/css?family=Fredericka+the+Great|Arapey|Roboto:400,700,400italic" rel="stylesheet" type="text/css"/><link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@10.7.2/styles/default.min.css"/><script src="https://unpkg.com/@highlightjs/cdn-assets@10.7.2/highlight.min.js"></script><script src="https://unpkg.com/@highlightjs/cdn-assets@10.7.2/languages/javascript.min.js"></script><script src="https://unpkg.com/@highlightjs/cdn-assets@10.7.2/languages/cpp.min.js"></script><script src="https://unpkg.com/@highlightjs/cdn-assets@10.7.2/languages/glsl.min.js"></script><link rel="stylesheet" href="/style/main.css"/><meta name="next-head-count" content="25"/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-381dbb3c33243b4920e6.js"></script><script src="/_next/static/chunks/webpack-17597d20e291f72b2439.js" defer=""></script><script src="/_next/static/chunks/framework-bdc1b4e5e48979e16d36.js" defer=""></script><script src="/_next/static/chunks/main-4ac108dd57980e4159e9.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c981e0e3ce59f13eb8d0.js" defer=""></script><script src="/_next/static/chunks/5988-738c1ea5f97353b6463e.js" defer=""></script><script src="/_next/static/chunks/pages/%5Byear%5D/%5Bmonth%5D/%5Bslug%5D-b78f23c90ce5148ef413.js" defer=""></script><script src="/_next/static/BU6ILFyKrVIRdGJGtqMwN/_buildManifest.js" defer=""></script><script src="/_next/static/BU6ILFyKrVIRdGJGtqMwN/_ssgManifest.js" defer=""></script><style id="__jsx-2519965637">.block.jsx-2519965637{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.block.jsx-2519965637 .right.jsx-2519965637{padding:10px;}.block.jsx-2519965637 .social.jsx-2519965637{margin-top:10px;}.block.jsx-2519965637 .social.jsx-2519965637 a.jsx-2519965637{padding:10px;}.block.jsx-2519965637 .social.jsx-2519965637 img.jsx-2519965637{height:20px;}</style><style id="__jsx-3621368397">.container.jsx-3621368397{min-height:100vh;padding:0 0.5rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}</style><style id="__jsx-3469673304">html,body{padding:0;margin:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto, Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue, sans-serif;}*{box-sizing:border-box;}a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}a:hover,a:active{-webkit-text-decoration:underline;text-decoration:underline;}</style></head><body><div id="__next"><div class="jsx-3621368397 container"><div id="container"><div id="main"><div id="content"><article><header><h1><a href="/">GNSP – the Nano screen rendering</a></h1><time class="date" dateTime="2022-02-14">2022-02-14</time><span class="tags"><a class="tag">NFT</a></span></header><div class="entry-content"><p>This third article (in a series of 7 articles) reveals the technique used to render the screen display itself.</p>
<p><video muted loop autoplay controls src="/images/2021/12/gnsp/419.mp4" width="50%" style="float:left; margin-right: 40px; margin-bottom:20px"></video></p>
<p><strong>Timeline:</strong></p>
<ul>
<li><a href="/2021/12/gnsp">article 1: GNSP – the concept</a></li>
<li><a href="/2021/12/gnsp-raymarching">article 2: the 3D distance to a Nano S+</a></li>
<li><a href="/2022/02/gnsp-nanoscreen"><strong>article 3: the nano screen</strong></a></li>
<li><a href="/2022/02/gnsp-swivel">article 4: the swivel</a></li>
<li>article 5: the background</li>
<li>article 6: the video generation</li>
<li>article 7: the final drop</li>
<li>(?March) public mint</li>
</ul>
<p><strong>The collection is browsable on <a href="https://greweb.me/gnsp">https://greweb.me/gnsp</a></strong></p>
<p><strong>OpenSea: <a href="https://opensea.io/collection/gnsp">https://opensea.io/collection/gnsp</a></strong></p>
<br style="clear:left"/>

<p>The screen, displays the unique BIP39 word and can sometimes have an effect or an animation. In the NFT metadata, they are expressed on the &quot;Screen&quot; feature, and here is the distribution:</p>
<pre><code>                 &lt;not defined&gt;: 1527 = 74.6%
                     scrolling: 251 = 12.3%
                      blinking: 136 = 6.6%
                      negative: 81 = 4.0%
                       complex: 25 = 1.2%
        negative and scrolling: 11 = 0.5%
                 half-negative: 8 = 0.4%
         negative and blinking: 7 = 0.3%
    half-negative and blinking: 2 = 0.1%
</code></pre>
<p>This means 75% of the time you will only get the text displayed statically but in other case you have various effects implemented.</p>
<h2 id="step-1-a-canvas2d-texture-is-used-for-the-word-text">Step 1: a Canvas2D texture is used for the word text</h2>
<p>a 128 by 64 Canvas 2D texture is generated – this is the actual resolution in pixels on the actual device.</p>
<pre><code class="language-js">function screen(word) {
  const w = 128; const h = 64;
  const canvas = document.createElement(&quot;canvas&quot;);
  canvas.width = w; canvas.height = h;
  const ctx = canvas.getContext(&quot;2d&quot;);
  ctx.fillStyle = &quot;#fff&quot;;
  ctx.fillRect(0, 0, w, h);
  ctx.textAlign = &quot;center&quot;;
  ctx.textBaseline = &quot;middle&quot;;
  ctx.font =
    (navigator.userAgent.includes(&quot;Mac OS&quot;)
      ? &quot;&quot; : &quot;bold &quot;) + &quot;22px Arial&quot;;
  ctx.fillStyle = &quot;#000&quot;;
  ctx.fillText(word, w / 2, h / 2);
  return canvas;
}
</code></pre>
<blockquote>
<p>Ok, there is a funny trick here on an annoying fact: depending on your OS you will have a different font weight, as Mac devices tend to have bolder font, I only used non bold in other cases. </p>
</blockquote>
<!--
I will explain in Article 6 why I actually needed to support different OSs during the video generation phase. I have also externalized the `document.createElement("canvas")` and `ctx.fillText` implementations into a function in order to be able to run this in Node.js (against node-canvas library).
-->

<p>Apart this trick, there are nothing fancy here: we are just writing the word in the Canvas. So there are actually no animation logic at all here: the animations (text motion / balls motion in negative) are all implemented in the GLSL shader.</p>
<h2 id="step-2-the-text-texture-is-processed-in-glsl">Step 2: the text texture is processed in GLSL</h2>
<p>I&#39;m using <code>regl</code> library helper and I need to inject the text canvas as a <code>uniform sampler2D text</code> parameter:</p>
<pre><code class="language-js">uniforms: {
  text: regl.texture({ data: screenCanvas, flipY: true }),
</code></pre>
<p>After this, the main trick is to project the 2D Texture of the word onto the 3D raymarched object, and in my case, I simply project it along the Z-axis, globally. Indeed it would need to be applied &quot;locally&quot; if the Nano was actually moving or rotating but I didn&#39;t need that so we can simply stick to a global mapping.</p>
<p>So basically:</p>
<pre><code class="language-glsl">vec2 coord = someOffset + someMultiplier * p.xy;
float m = step(texture2D(text, coord).x, 0.5);
</code></pre>
<p>makes <code>m</code> being a value of either 0.0 or 1.0 based on if the pixel is on or off.</p>
<p>Now, it also need to be pixelated, so we need to round the coordinate:</p>
<pre><code class="language-glsl">vec2 coord = someOffset + someMultiplier * p.xy;
vec2 a = coord * vec2(128.,64.);
coord = floor(a) / vec2(128.,64.);
float m = step(texture2D(text, coord).x, 0.5);
</code></pre>
<p>Then we add a <code>edge</code> effect. This <code>edge</code> represents the distance to the edge of a pixel.</p>
<pre><code class="language-glsl">vec2 coord = someOffset + someMultiplier * p.xy;
vec2 a = coord * vec2(128.,64.);
float edge = min(fract(a.x), fract(a.y));
coord = floor(a) / vec2(128.,64.);
float m = step(texture2D(text, coord).x, 0.5)
  * (1.0 - 0.5 * step(edge, 0.25)); // changes the pixel color
</code></pre>
<p>This will accentuate even more the pixel effect as we can see in this zoom:</p>
<img src="/images/2022/gnsp/pixel.png" width="100%"/>

<p>Ok, to precise exactly what <code>coord</code> is, here is the actual code:</p>
<pre><code class="language-glsl">vec2 coord = fract(fract(vec2(-0.2, 0.5) + vec2(3.6) * p.xy / vec2(-2.25, 1.0)) + ${
  opts.scrollingScreen ? &quot;vec2(0.5+floor(time*15.0)/15.0, 0.)&quot; : &quot;0.0&quot;
});
</code></pre>
<p>You can note that:</p>
<ul>
<li>multiply by <code>vec2(-2.25, 1.0)</code> to stretch a bit the font.</li>
<li>in case of <code>scrollingScreen</code> an offset by <code>time</code> is applied on x coordinate, and using some floor function so it does it by &quot;increments&quot; (pixel scroll)</li>
<li>we apply a whole <code>fract</code> function (which is a <code>% 1.0</code>) to keep the coord in a 0.0 - 1.0 range and actually make it repeat.</li>
</ul>
<p>Now, to create the negative effect, what we simply need to do is to either chose <code>m</code> or <code>1.0 - m</code> as a pixel value. </p>
<p>This is implementing the simple idea to have half of the screen cut into two negative parts:</p>
<pre><code class="language-glsl">${opts.halfnegativeScreen ? &quot;m=mix(m,1.-m,step(coord.y, 0.5));&quot; : &quot;&quot;}
</code></pre>
<p>And this implements the possibly blinking effect:</p>
<pre><code class="language-glsl">${opts.blinkingScreen ? &quot;m*=step(fract(2.*time),0.5);&quot; : &quot;&quot;}
</code></pre>
<p>Now for the more complex animation, the effect varies at a given position on x,y, so we will give it to a function to determine if we need to swap the color. The animation we can see in the video above is a reference to one of my last year creation: <a href="/shaderday/65">/shaderday/65</a>.</p>
<pre><code class="language-glsl">${
  !opts.screenAnimation
    ? &quot;&quot;
    : `
      float sz = ${(
        1 -
        opts.screenAnimation[3] * opts.screenAnimation[3]
      ).toFixed(2)};
      coord -= 0.5;
      coord *= vec2(2.,1.) * ${(
        1 -
        opts.screenAnimation[3] * opts.screenAnimation[3]
      ).toFixed(2)};
      coord += 0.5;
      ${
        opts.screenAnimation[1] &lt; 0.2
          ? `coord.y${opts.screenAnimation[1] &lt; 0.1 ? &quot;+&quot; : &quot;-&quot;}=time;`
          : &quot;&quot;
      }
      ${opts.screenAnimation[2] &lt; 0.2 ? `coord.x-=time;` : &quot;&quot;}
      coord=fract(coord);
      m=mix(m,1.-m,step(shape(coord,2.*PI*time), 0.5));
    `
}
</code></pre>
<p><code>screenAnimation</code> is a array of random values and with that, we can yield variation of the initial <code>shape</code> animation which is implemented relatively like in my <a href="/shaderday/65">/shaderday/65</a>:</p>
<pre><code class="language-glsl">float shape (vec2 p, float t) {
  float smoothing = 0.15;
  p -= 0.5;
  vec2 q = p;
  pR(p, t + cos(${Math.round(5 * opts.screenAnimation[0] - 2)}. * t));
  vec2 dist = vec2(0.0);
  float crop = 99.0;
  float s = 99.0;;
  s = fOpUnionRound(q.y, s, smoothing);
dist = vec2(0.31, 0.0);
float radius = 0.11;
s = fOpUnionRound(s, length(p + dist) - radius, smoothing);
crop = fOpUnionRound(crop, length(p - dist) - radius, smoothing);
  s = fOpDifferenceRound(s, crop, smoothing);
  return smoothstep(0.0, 1.0 / min(resolution.x, resolution.y), s);
}
</code></pre>
<p>Finally, we map the &quot;m&quot; value to actual colors, and in our case it&#39;s basically black and white. Note the usage of <code>negativeScreen</code> flag:</p>
<pre><code class="language-glsl">mix(
  vec3(0.01),
  vec3(1.0),
  ${opts.negativeScreen ? &quot;1.-&quot; : &quot;&quot;}m
)
</code></pre>
<blockquote>
<p>This GLSL code is templated in JavaScript as you may notice, it&#39;s a trick to make the GLSL compile even faster to avoid having runtime ifs.</p>
</blockquote>
<p><strong>That&#39;s it folks! There are nothing more to say about the screen rendering of GNSP.</strong></p>
<!--
// TODO explain multi platform in VIDEO article

```js
uniforms: { text: regl.texture(createImageTexture(screenCanvas))
```

where `createImageTexture` in context of web is:

```js
let createImageTexture = canvas => ({ data: canvas, flipY: true })
```

but for instance, in context of Node.js implementation is:

```js
let createImageTexture = (canvas) => {
  const ctx = canvas.getContext("2d");
  const width = canvas.width;
  const height = canvas.height;
  const imageData = ctx.getImageData(0, 0, width, height);
  return { data: imageData.data, width, height };
};
```
---></div><footer><div class="jsx-2519965637 block"><img src="http://greweb.me/logo.svg" width="100" class="jsx-2519965637"/><div class="jsx-2519965637 right"><div class="jsx-2519965637 description">generative artist. doodling with algorithms (creative coding). shaders &amp; fountain pens robot plotting.</div><div class="jsx-2519965637 social"><a href="https://twitter.com/greweb" class="jsx-2519965637"><img alt="" src="/icons/twitter.svg" class="jsx-2519965637"/></a><a href="https://instagram.com/greweb" class="jsx-2519965637"><img alt="" src="/icons/instagram.svg" class="jsx-2519965637"/></a><a href="https://twitch.tv/greweb" class="jsx-2519965637"><img alt="" src="/icons/twitch.svg" class="jsx-2519965637"/></a><a href="https://github.com/gre" class="jsx-2519965637"><img alt="" src="/icons/github.svg" class="jsx-2519965637"/></a><a href="https://opensea.io/greweb" class="jsx-2519965637"><img alt="" src="/icons/eth.svg" class="jsx-2519965637"/></a><a href="https://objkt.com/profile/tz1cgQAQfECg5bPASYTMyJ9QJQjSUi8rfL67" class="jsx-2519965637"><img alt="" src="/icons/tz.svg" class="jsx-2519965637"/></a><a href="https://fxhash.xyz/u/greweb" class="jsx-2519965637"><img alt="" src="/icons/tz.svg" class="jsx-2519965637"/></a><a href="https://greweb.itch.io" class="jsx-2519965637"><img alt="" src="/icons/iconmonstr-gamepad-3.svg" class="jsx-2519965637"/></a></div></div></div></footer></article></div></div></div><script>hljs.highlightAll();</script></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"id":"2022-02-14-gnsp-nanoscreen","year":"2022","month":"02","day":"14","slug":"gnsp-nanoscreen","content":"\u003cp\u003eThis third article (in a series of 7 articles) reveals the technique used to render the screen display itself.\u003c/p\u003e\n\u003cp\u003e\u003cvideo muted loop autoplay controls src=\"/images/2021/12/gnsp/419.mp4\" width=\"50%\" style=\"float:left; margin-right: 40px; margin-bottom:20px\"\u003e\u003c/video\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eTimeline:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/2021/12/gnsp\"\u003earticle 1: GNSP – the concept\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/2021/12/gnsp-raymarching\"\u003earticle 2: the 3D distance to a Nano S+\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/2022/02/gnsp-nanoscreen\"\u003e\u003cstrong\u003earticle 3: the nano screen\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/2022/02/gnsp-swivel\"\u003earticle 4: the swivel\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003earticle 5: the background\u003c/li\u003e\n\u003cli\u003earticle 6: the video generation\u003c/li\u003e\n\u003cli\u003earticle 7: the final drop\u003c/li\u003e\n\u003cli\u003e(?March) public mint\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cstrong\u003eThe collection is browsable on \u003ca href=\"https://greweb.me/gnsp\"\u003ehttps://greweb.me/gnsp\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eOpenSea: \u003ca href=\"https://opensea.io/collection/gnsp\"\u003ehttps://opensea.io/collection/gnsp\u003c/a\u003e\u003c/strong\u003e\u003c/p\u003e\n\u003cbr style=\"clear:left\"/\u003e\n\n\u003cp\u003eThe screen, displays the unique BIP39 word and can sometimes have an effect or an animation. In the NFT metadata, they are expressed on the \u0026quot;Screen\u0026quot; feature, and here is the distribution:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e                 \u0026lt;not defined\u0026gt;: 1527 = 74.6%\n                     scrolling: 251 = 12.3%\n                      blinking: 136 = 6.6%\n                      negative: 81 = 4.0%\n                       complex: 25 = 1.2%\n        negative and scrolling: 11 = 0.5%\n                 half-negative: 8 = 0.4%\n         negative and blinking: 7 = 0.3%\n    half-negative and blinking: 2 = 0.1%\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis means 75% of the time you will only get the text displayed statically but in other case you have various effects implemented.\u003c/p\u003e\n\u003ch2 id=\"step-1-a-canvas2d-texture-is-used-for-the-word-text\"\u003eStep 1: a Canvas2D texture is used for the word text\u003c/h2\u003e\n\u003cp\u003ea 128 by 64 Canvas 2D texture is generated – this is the actual resolution in pixels on the actual device.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-js\"\u003efunction screen(word) {\n  const w = 128; const h = 64;\n  const canvas = document.createElement(\u0026quot;canvas\u0026quot;);\n  canvas.width = w; canvas.height = h;\n  const ctx = canvas.getContext(\u0026quot;2d\u0026quot;);\n  ctx.fillStyle = \u0026quot;#fff\u0026quot;;\n  ctx.fillRect(0, 0, w, h);\n  ctx.textAlign = \u0026quot;center\u0026quot;;\n  ctx.textBaseline = \u0026quot;middle\u0026quot;;\n  ctx.font =\n    (navigator.userAgent.includes(\u0026quot;Mac OS\u0026quot;)\n      ? \u0026quot;\u0026quot; : \u0026quot;bold \u0026quot;) + \u0026quot;22px Arial\u0026quot;;\n  ctx.fillStyle = \u0026quot;#000\u0026quot;;\n  ctx.fillText(word, w / 2, h / 2);\n  return canvas;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cblockquote\u003e\n\u003cp\u003eOk, there is a funny trick here on an annoying fact: depending on your OS you will have a different font weight, as Mac devices tend to have bolder font, I only used non bold in other cases. \u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c!--\nI will explain in Article 6 why I actually needed to support different OSs during the video generation phase. I have also externalized the `document.createElement(\"canvas\")` and `ctx.fillText` implementations into a function in order to be able to run this in Node.js (against node-canvas library).\n--\u003e\n\n\u003cp\u003eApart this trick, there are nothing fancy here: we are just writing the word in the Canvas. So there are actually no animation logic at all here: the animations (text motion / balls motion in negative) are all implemented in the GLSL shader.\u003c/p\u003e\n\u003ch2 id=\"step-2-the-text-texture-is-processed-in-glsl\"\u003eStep 2: the text texture is processed in GLSL\u003c/h2\u003e\n\u003cp\u003eI\u0026#39;m using \u003ccode\u003eregl\u003c/code\u003e library helper and I need to inject the text canvas as a \u003ccode\u003euniform sampler2D text\u003c/code\u003e parameter:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-js\"\u003euniforms: {\n  text: regl.texture({ data: screenCanvas, flipY: true }),\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAfter this, the main trick is to project the 2D Texture of the word onto the 3D raymarched object, and in my case, I simply project it along the Z-axis, globally. Indeed it would need to be applied \u0026quot;locally\u0026quot; if the Nano was actually moving or rotating but I didn\u0026#39;t need that so we can simply stick to a global mapping.\u003c/p\u003e\n\u003cp\u003eSo basically:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003evec2 coord = someOffset + someMultiplier * p.xy;\nfloat m = step(texture2D(text, coord).x, 0.5);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003emakes \u003ccode\u003em\u003c/code\u003e being a value of either 0.0 or 1.0 based on if the pixel is on or off.\u003c/p\u003e\n\u003cp\u003eNow, it also need to be pixelated, so we need to round the coordinate:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003evec2 coord = someOffset + someMultiplier * p.xy;\nvec2 a = coord * vec2(128.,64.);\ncoord = floor(a) / vec2(128.,64.);\nfloat m = step(texture2D(text, coord).x, 0.5);\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThen we add a \u003ccode\u003eedge\u003c/code\u003e effect. This \u003ccode\u003eedge\u003c/code\u003e represents the distance to the edge of a pixel.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003evec2 coord = someOffset + someMultiplier * p.xy;\nvec2 a = coord * vec2(128.,64.);\nfloat edge = min(fract(a.x), fract(a.y));\ncoord = floor(a) / vec2(128.,64.);\nfloat m = step(texture2D(text, coord).x, 0.5)\n  * (1.0 - 0.5 * step(edge, 0.25)); // changes the pixel color\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will accentuate even more the pixel effect as we can see in this zoom:\u003c/p\u003e\n\u003cimg src=\"/images/2022/gnsp/pixel.png\" width=\"100%\"/\u003e\n\n\u003cp\u003eOk, to precise exactly what \u003ccode\u003ecoord\u003c/code\u003e is, here is the actual code:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003evec2 coord = fract(fract(vec2(-0.2, 0.5) + vec2(3.6) * p.xy / vec2(-2.25, 1.0)) + ${\n  opts.scrollingScreen ? \u0026quot;vec2(0.5+floor(time*15.0)/15.0, 0.)\u0026quot; : \u0026quot;0.0\u0026quot;\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eYou can note that:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003emultiply by \u003ccode\u003evec2(-2.25, 1.0)\u003c/code\u003e to stretch a bit the font.\u003c/li\u003e\n\u003cli\u003ein case of \u003ccode\u003escrollingScreen\u003c/code\u003e an offset by \u003ccode\u003etime\u003c/code\u003e is applied on x coordinate, and using some floor function so it does it by \u0026quot;increments\u0026quot; (pixel scroll)\u003c/li\u003e\n\u003cli\u003ewe apply a whole \u003ccode\u003efract\u003c/code\u003e function (which is a \u003ccode\u003e% 1.0\u003c/code\u003e) to keep the coord in a 0.0 - 1.0 range and actually make it repeat.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eNow, to create the negative effect, what we simply need to do is to either chose \u003ccode\u003em\u003c/code\u003e or \u003ccode\u003e1.0 - m\u003c/code\u003e as a pixel value. \u003c/p\u003e\n\u003cp\u003eThis is implementing the simple idea to have half of the screen cut into two negative parts:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003e${opts.halfnegativeScreen ? \u0026quot;m=mix(m,1.-m,step(coord.y, 0.5));\u0026quot; : \u0026quot;\u0026quot;}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eAnd this implements the possibly blinking effect:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003e${opts.blinkingScreen ? \u0026quot;m*=step(fract(2.*time),0.5);\u0026quot; : \u0026quot;\u0026quot;}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow for the more complex animation, the effect varies at a given position on x,y, so we will give it to a function to determine if we need to swap the color. The animation we can see in the video above is a reference to one of my last year creation: \u003ca href=\"/shaderday/65\"\u003e/shaderday/65\u003c/a\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003e${\n  !opts.screenAnimation\n    ? \u0026quot;\u0026quot;\n    : `\n      float sz = ${(\n        1 -\n        opts.screenAnimation[3] * opts.screenAnimation[3]\n      ).toFixed(2)};\n      coord -= 0.5;\n      coord *= vec2(2.,1.) * ${(\n        1 -\n        opts.screenAnimation[3] * opts.screenAnimation[3]\n      ).toFixed(2)};\n      coord += 0.5;\n      ${\n        opts.screenAnimation[1] \u0026lt; 0.2\n          ? `coord.y${opts.screenAnimation[1] \u0026lt; 0.1 ? \u0026quot;+\u0026quot; : \u0026quot;-\u0026quot;}=time;`\n          : \u0026quot;\u0026quot;\n      }\n      ${opts.screenAnimation[2] \u0026lt; 0.2 ? `coord.x-=time;` : \u0026quot;\u0026quot;}\n      coord=fract(coord);\n      m=mix(m,1.-m,step(shape(coord,2.*PI*time), 0.5));\n    `\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003ccode\u003escreenAnimation\u003c/code\u003e is a array of random values and with that, we can yield variation of the initial \u003ccode\u003eshape\u003c/code\u003e animation which is implemented relatively like in my \u003ca href=\"/shaderday/65\"\u003e/shaderday/65\u003c/a\u003e:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003efloat shape (vec2 p, float t) {\n  float smoothing = 0.15;\n  p -= 0.5;\n  vec2 q = p;\n  pR(p, t + cos(${Math.round(5 * opts.screenAnimation[0] - 2)}. * t));\n  vec2 dist = vec2(0.0);\n  float crop = 99.0;\n  float s = 99.0;;\n  s = fOpUnionRound(q.y, s, smoothing);\ndist = vec2(0.31, 0.0);\nfloat radius = 0.11;\ns = fOpUnionRound(s, length(p + dist) - radius, smoothing);\ncrop = fOpUnionRound(crop, length(p - dist) - radius, smoothing);\n  s = fOpDifferenceRound(s, crop, smoothing);\n  return smoothstep(0.0, 1.0 / min(resolution.x, resolution.y), s);\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eFinally, we map the \u0026quot;m\u0026quot; value to actual colors, and in our case it\u0026#39;s basically black and white. Note the usage of \u003ccode\u003enegativeScreen\u003c/code\u003e flag:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-glsl\"\u003emix(\n  vec3(0.01),\n  vec3(1.0),\n  ${opts.negativeScreen ? \u0026quot;1.-\u0026quot; : \u0026quot;\u0026quot;}m\n)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThis GLSL code is templated in JavaScript as you may notice, it\u0026#39;s a trick to make the GLSL compile even faster to avoid having runtime ifs.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003cstrong\u003eThat\u0026#39;s it folks! There are nothing more to say about the screen rendering of GNSP.\u003c/strong\u003e\u003c/p\u003e\n\u003c!--\n// TODO explain multi platform in VIDEO article\n\n```js\nuniforms: { text: regl.texture(createImageTexture(screenCanvas))\n```\n\nwhere `createImageTexture` in context of web is:\n\n```js\nlet createImageTexture = canvas =\u003e ({ data: canvas, flipY: true })\n```\n\nbut for instance, in context of Node.js implementation is:\n\n```js\nlet createImageTexture = (canvas) =\u003e {\n  const ctx = canvas.getContext(\"2d\");\n  const width = canvas.width;\n  const height = canvas.height;\n  const imageData = ctx.getImageData(0, 0, width, height);\n  return { data: imageData.data, width, height };\n};\n```\n---\u003e","data":{"title":"GNSP – the Nano screen rendering","thumbnail":"/images/2022/gnsp/screen-thumbnail.png","description":"This third article reveals the technique used to render the screen display itself.","tags":["NFT"]}},"__N_SSG":true},"page":"/[year]/[month]/[slug]","query":{"year":"2022","month":"02","slug":"gnsp-nanoscreen"},"buildId":"BU6ILFyKrVIRdGJGtqMwN","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>